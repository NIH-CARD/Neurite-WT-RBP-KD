---
title: Differential expression analysis
output:
    html_document:
        code_folding: hide
        toc: true
        toc_float: true
        toc_depth: 3
params:
    contrast_name: ''
    neurite_contrast: ''
    soma_contrast: ''
---

```{r global_options, include=FALSE}
# Sets up global options for rendering RMarkdown into HTML.
system("export TMPDIR=/lscratch/$SLURM_JOB_ID")
knitr::opts_chunk$set(
    warning=FALSE,
    message=FALSE,
    cache.extra_file_dep_1 = file.info('../config/sampletable.tsv')$mtime,
    cache.extra_file_dep_2 = file.info('../data/rnaseq_aggregation/featurecounts_features.txt')$mtime,
    cache.extra_file_dep_3 = file.info('../data/rnaseq_samples/*/*.kallisto/abundance.h5')$mtime,
    cache.extra_file_dep_4 = file.info('../data/rnaseq_samples/*/*.salmon/quant.sf')$mtime
)
```

```{r lcdbwf, results='hide'}
# Load the lcdbwf R package, which is stored locally.
# This package has many custom functions used throughout this document.
devtools::document('../../../lib/lcdbwf')
devtools::load_all('../../../lib/lcdbwf')
```


```{r config}

# HOW TO CONFIGURE ------------------------------------------------------
# Any chunks below that depend on config options should be cached and use one
# or more sections of the config object as arbitrary additional chunk options.
# By convention, we use the argument name "config" although there is nothing
# special about this name e.g.,
#
#      {r, cache=TRUE, config=config$annotation}
#
# Thereafter, any changes to config options under the "annotation" section will then
# invalidate that chunk's cache -- along with any other chunks that also have
# config$annotation included as a chunk option.
#
config <- lcdbwf:::load_config('config.yaml')

# To keep this Rmd streamlined, much of the text is stored in a different file,
# text.yaml, and accessed via the `text` list after it is loaded here.
text <- yaml::yaml.load_file('text.yaml')

# Initialixe ags 
contrast_name <- params$contrast_name
neurite_contrast <- params$neurite_contrast
soma_contrast <- params$soma_contrast
```


# Changelog

**Initial results**

Last run: `r date()`

```{r coldata_setup}
# Set up all of the metadata for the samples and experimental design. Use this
# chunk to modify if needed.
# https://bioconductor.org/packages/devel/bioc/vignettes/tximeta/inst/doc/tximeta.html
# Normally don't recommend this but if we want everything to be consistent it is important to
# use the same gtf files rather than having them downloaded automatically.
colData <- read.table(config$main$sampletable, sep='\t', header=TRUE, stringsAsFactors=FALSE)

# lcdb-wf requires that the first column of the sampletable contain sample
# names. Use that to set the rownames.
rownames(colData) <- colData[,1]
```

```{r dds_initial, cache=FALSE, config=c(config$main, config$toggle$salmon, config$toggle$kallisto)}
# Convert featureCounts transcript-level counts into DESeq2 object, and run
# variance-stabiliizing transform.
# Will likely need to find a way to run salmon quant to combine the collapsable samples to 
# do that like this:
# salmon quant -i transcripts_index -l <LIBTYPE> \
#  -1 reads01_1.fq  reads02_1.fq \
#  -2 reads01_2.fq reads02_2.fq \
#  -o sample
# Will need to make a dataframe like this for the sampletable: https://support.bioconductor.org/p/9149213/
# use fishpond 
library(tximeta)
library(data.table)

dir <- '/data/CARD_ARDIS/2023_07_21_veronica_analysis/workflows/rnaseq/references_data/references_data/human/gencode-v28/'
indexDir <- file.path(dir, "transcriptome/salmon/human_gencode-v28/")
gtfPath <- file.path(dir, "annotation/human_gencode-v28.gtf")
fastaPath <- file.path(dir, "genome/human_gencode-v28.fasta")

salmon_dir <- '/data/CARD_ARDIS/2023_07_21_veronica_analysis/workflows/rnaseq/data/rnaseq_samples/'
dt_colData <- setDT(colData)
dt_colData[, names:=bio_group]


# Remove lane two rows since we already collapsed by bio_group when making salmon files
dt_colData <- dt_colData[!duplicated(dt_colData, by="bio_group")]
# Add salmon file paths
dt_colData[, files:= paste0(salmon_dir, bio_group, '.salmon/quant.sf')]

dt_colData_WT <- dt_colData[full_guide_grp %in% c(neurite_contrast, soma_contrast),]

# Set conditions for this round
dt_colData_WT$cellular_zone <- factor(dt_colData_WT$full_guide_grp ,levels=c(neurite_contrast, soma_contrast))
```

```{r tximeta_setup, config=c(config$main, config$toggle$salmon, config$toggle$kallisto)}

# Just like lcdb_wf ignore the version number
# Use the full version for calculations outside of just one group
se_full_data <- tximeta(dt_colData, ignoreTxVersion=True, txOut=TRUE)
se_full_data_no_WT <- tximeta(dt_colData[!(guide_group == 'WT')], ignoreTxVersion=TRUE, txOut=TRUE)
se <- tximeta(dt_colData_WT, ignoreTxVersion=TRUE, txOut=TRUE)
no_WT_se <- tximeta(dt_colData_WT[!(guide_group == 'WT')], ignoreTxVersion=TRUE, txOut=TRUE)

# library(org.Hs.eg.db)
# se <- addIds(se,"REFSEQ",gene=FALSE)

# Rename for the statistical portion
y <- se
y_no_WT <- no_WT_se
y_full <- se_full_data
y_full_no_WT <- se_full_data_no_WT

library(DESeq2)
library(ggplot2)
library(dplyr)



ya <- DESeqDataSet(y, design = ~1)
vsd <- varianceStabilizingTransformation(ya, blind=TRUE)
ya_full <- DESeqDataSet(y_full, design = ~1)
vsd_full <- varianceStabilizingTransformation(ya_full, blind=TRUE)
ya_full_no_WT <- DESeqDataSet(y_full_no_WT, design = ~1)
vsd_full_no_WT <- varianceStabilizingTransformation(ya_full_no_WT, blind=TRUE)

# Make new column for targeting vs nontargeting guide
colData(vsd_full)$targeting <- case_match(colData(vsd_full)$guide_group, 
                                     c('sg100', 'sg1126') ~ 'non-targeting',
                                     c('sg200', 'sg1152', 'sg1128') ~ 'targeting',
                                     'WT' ~ 'WT',
                                     )
colData(vsd_full_no_WT)$targeting <- case_match(colData(vsd_full_no_WT)$guide_group, 
                                     c('sg100', 'sg1126') ~ 'non-targeting',
                                     c('sg200', 'sg1152', 'sg1128') ~ 'targeting',
                                     'WT' ~ 'WT',
                                     )

write_tsv(rownames_to_column((as.data.frame(assays(y_full)$counts)), "transcript"), "test_counts_full.tsv")
```

```{r PCA,config=c(config$main, config$toggle$salmon, config$toggle$kallisto)}

library("pcaExplorer")
#PCA without correction
pca_matrix_full<- as.data.frame(assay(vsd_full)) %>%
    base::as.matrix() %>%
    t()
sample_pca_full <- prcomp(pca_matrix_full)

pca_matrix_full_no_WT<- as.data.frame(assay(vsd_full_no_WT)) %>%
    base::as.matrix() %>%
    t()
sample_pca_full_no_WT <- prcomp(pca_matrix_full_no_WT)

# HAven't satandarzied yet
pc_scores_full <- sample_pca_full$x %>% as_tibble(rownames="sample")
pc_scores_full_no_WT <- sample_pca_full_no_WT$x %>% as_tibble(rownames="sample")

# Change variables in order to generate PCA plots
variable <- c('zone')
PC1 <- 1
PC2 <- 2
first_PC <- paste0('PC', PC1)
second_PC <- paste0('PC', PC2)
color_var <- if(variable == 'group') 'group.1' else variable # group is similar to the internal var

pc_metadata <- inner_join(pc_scores, dt_colData_WT, join_by(sample == names))
pc_metadata_full <- inner_join(pc_scores_full, dt_colData, join_by(sample == names))
pc_metadata_full_no_WT <- inner_join(pc_scores_full_no_WT, dt_colData, join_by(sample == names))
mat <- DESeq2::plotPCA(vsd, c(variable, 'targeting'), pcsToUse=PC1:PC2, returnData=TRUE)
mat_full <- DESeq2::plotPCA(vsd_full, c(variable, 'targeting'), pcsToUse=PC1:PC2, returnData=TRUE)
mat_full_no_WT <- DESeq2::plotPCA(vsd_full_no_WT, c(variable, 'targeting'), pcsToUse=PC1:PC2, returnData=TRUE)
pv <- attr(mat, 'percentVar')
pv_full <- attr(mat_full, 'percentVar')
pv_full_no_WT <- attr(mat_full_no_WT, 'percentVar')

p <- ggplot(data=mat,aes_string(x = first_PC, y = second_PC, color = color_var, shape='targeting')) +
    scale_shape_manual(values=c(4,16, 0)) +
geom_point(size=3) + xlab(paste0(first_PC,': ', round(pv[1]*100), '% variance')) +
          ylab(paste0(second_PC,': ', round(pv[2]*100), '% variance')) + coord_fixed() +
          ggtitle(paste0(variable, " , ", first_PC, " and ", second_PC, " all samples"))
ggsave(paste0("PCA_plots/", variable, "_pca_",first_PC, "_", second_PC, "_with_WT.pdf"), plot=p)

# For the full dataset
p_full <- ggplot(data=mat_full,aes_string(x = first_PC, y = second_PC, color = color_var, shape='targeting')) +
    scale_shape_manual(values=c(4,16, 0)) +
geom_point(size=3) + xlab(paste0(first_PC,': ', round(pv_full[1]*100), '% variance')) +
          ylab(paste0(second_PC,': ', round(pv_full[2]*100), '% variance')) + coord_fixed() +
          ggtitle(paste0(variable, " , ", first_PC, " and ", second_PC, " all samples"))
ggsave(paste0("PCA_plots/", variable, "_pca_",first_PC, "_", second_PC, "full_with_WT.pdf"), plot=p_full)

p_full_no_WT <- ggplot(data=mat_full_no_WT,aes_string(x = first_PC, y = second_PC, color = color_var, shape='targeting')) +
    scale_shape_manual(values=c(4,16, 0)) +
geom_point(size=3) + xlab(paste0(first_PC,': ', round(pv_full_no_WT[1]*100), '% variance')) +
          ylab(paste0(second_PC,': ', round(pv_full_no_WT[2]*100), '% variance')) + coord_fixed() +
          ggtitle(paste0(variable, " , ", first_PC, " and ", second_PC, " all samples"))
ggsave(paste0("PCA_plots/", variable, "_pca_",first_PC, "_", second_PC, "full_with_no_WT.pdf"), plot=p_full_no_WT)
```

```{r swish,onfig=c(config$main, config$toggle$salmon, config$toggle$kallisto)}

library(fishpond)
library(tibble)
y <- scaleInfReps(y)
y <- labelKeep(y)
y <- y[mcols(y)$keep,]
set.seed(1)

y <- swish(y, x="cellular_zone", pair="pair")

# Get the rows with an FDR in the 5% level
sign_tran <- y[mcols(y)$qvalue< 0.05]
df <- mcols(y)
df$tx_name <- rownames(df)
sign_tran <- as.tibble(df)
sign_tran <- sign_tran[sign_tran$qvalue < 0.05,]
# Must arrange by something for transite. Must specify what that is. They suggest log2FC
sign_tran <- dplyr::arrange(sign_tran, log2FC, locfdr)
sign_out <- apply(sign_tran, 2, as.character)
write.csv(sign_out, paste0("diff_tran", contrast_name, ".csv"), quote=FALSE, row.names=FALSE)
```

```{r transite, onfig=c(config$main, config$toggle$salmon, config$toggle$kallisto)}
library(transite)

library(biomaRt)
ensembl <- useEnsembl(biomart = "genes", dataset = "hsapiens_gene_ensembl", mirror='useast')
#search for terms
i <- searchAttributes(mart=ensembl, pattern="RefSeq")
i[1:20,]
# The below just converts references
#refseq_res <- getBM(attributes = c('ensembl_transcript_id_version', 'refseq_mrna'),
#      filters = 'ensembl_transcript_id_version',
#      values = sign_tran$tx_name,
#      mart = ensembl)

# We'll try with cdna and 3'UTR, and maybe with full transcript which is transcript_exon_intron

# Just trying to get all of sign_tran
rows <- nrow(sign_tran)
tran1 <- sign_tran[1:2000,]
subs <- gsub("\\..*","", tran1$tx_name)
sequences_tei_1 <- getSequence(id=subs, mart=ensembl, seqType='transcript_exon_intron', type='ensembl_transcript_id')
#
# delete file first if it exists to be sure it's new
transcripts_file <- paste0("transcripts_", contrast_name, ".csv")
if (file.exists(transcripts_file)) {file.remove(transcripts_file)}

write.table(sequences_tei_1, paste0("transcripts_",contrast_name,".csv"), quote=FALSE, sep=',', row.names=FALSE)
tran2 <- sign_tran[2001:4000,]
subs <- gsub("\\..*","", tran2$tx_name)
sequences_tei_2 <- getSequence(id=subs, mart=ensembl, seqType='transcript_exon_intron', type='ensembl_transcript_id')
write.table(sequences_tei_2, paste0("transcripts_",contrast_name,".csv"), append=TRUE, quote=FALSE, sep=',', row.names=FALSE)
tran3 <- sign_tran[4001:6000,]
subs <- gsub("\\..*","", tran3$tx_name)
sequences_tei_3 <- getSequence(id=subs, mart=ensembl, seqType='transcript_exon_intron', type='ensembl_transcript_id')
write.table(sequences_tei_3, paste0("transcripts_",contrast_name,".csv"), append=TRUE, quote=FALSE, sep=',', row.names=FALSE)
tran4 <- sign_tran[6001:8000,]
subs <- gsub("\\..*","", tran4$tx_name)
sequences_tei_4 <- getSequence(id=subs, mart=ensembl, seqType='transcript_exon_intron', type='ensembl_transcript_id')
write.table(sequences_tei_4, paste0("transcripts_",contrast_name,".csv"), append=TRUE, quote=FALSE, sep=',', row.names=FALSE)
tran5 <- sign_tran[8001:10000,]
subs <- gsub("\\..*","", tran5$tx_name)
sequences_tei_5 <- getSequence(id=subs, mart=ensembl, seqType='transcript_exon_intron', type='ensembl_transcript_id')
write.table(sequences_tei_5, paste0("transcripts_",contrast_name,".csv"), append=TRUE, quote=FALSE, sep=',', row.names=FALSE)
tran6 <- sign_tran[10001:rows,]
subs <- gsub("\\..*","", tran6$tx_name)
sequences_tei_6 <- getSequence(id=subs, mart=ensembl, seqType='transcript_exon_intron', type='ensembl_transcript_id')
write.table(sequences_tei_6, paste0("transcripts_",contrast_name,".csv"), append=TRUE, quote=FALSE, sep=',', row.names=FALSE)

library(readr)
library(stringr)
library(dplyr)

seqs_df <- read_csv(paste0("transcripts_",contrast_name,".csv"))
seqs_df <- seqs_df[,c(2,1)]
# get tx names from sign_tran
subs <- gsub("\\..*","", sign_tran$tx_name)
# Convert to RNA and order according to fdr in sign_tran
seqs_df <- seqs_df %>%
    mutate(across("transcript_exon_intron", \(x) str_replace_all(x, "T", "U"))) %>%
    arrange(match(ensembl_transcript_id, subs))

# Turn seqs into named vector
# Will still need to pull out the ensembl_transcript_ids at the end
seqs <- tibble::deframe(seqs_df)
seqs <- seqs[names(seqs) != "ensembl_transcript_id"]
# Remove bad characters
seqs <- seqs[!grepl("N",seqs)]

# Don't forget to set TMPDIR on the command line with some lscratch. Export TMPDIR=/lscratch/$SLURM_JOB_ID
# # The real trick is to make sure there are no NA values
result <- run_kmer_spma(seqs, sign_tran$log2FC,transcript_values_label="log2FC",n_cores=20)
saveRDS(result, paste0(contrast_name,".rds"))
```

# Session info
For reproducibility purposes, here is the output of `sessionInfo()` showing the
versions of all packages used here.

```{r sessioninfo}
sessionInfo()
```
